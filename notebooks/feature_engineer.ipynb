{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['plot']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import glob\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import binned_statistic, linregress\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from s3_connect import s3_connect\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "tmp_localdir = '~/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data From S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbed demos/loan-risk/data/raw_data.p from S3. Local file demos/loan-risk/data/raw_data.p is now available.\n"
     ]
    }
   ],
   "source": [
    "s3_conn = s3_connect(access=os.environ['AWS_CLOUD_BUCKET_KEY'],\n",
    "                     secret=os.environ['AWS_CLOUD_BUCKET_SECRET_KEY'],\n",
    "                     bucketname='ds-cloud-public-shared')\n",
    "\n",
    "df = s3_conn.pull_pickle_from_s3(key='demos/loan-risk/data/raw_data.p',tmp_localdir=tmp_localdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Include only fully paid or default\n",
    "if 'loan_status' in df:\n",
    "    df = df.ix[(df['loan_status']=='Fully Paid') | (df['loan_status']=='Charged Off')]\n",
    "    # Create binary label\n",
    "    df['default'] = df['loan_status'].map(lambda x: int(x=='Charged Off'))\n",
    "\n",
    "# Convert to datetime\n",
    "if 'issue_d' in df:\n",
    "    df['issue_d'] = pd.to_datetime(df['issue_d'],format='%b-%Y')\n",
    "\n",
    "    # Include only loans from 2008 to 2016 (so we have plenty of time to observe a default)\n",
    "    df = df.ix[(df['issue_d']>='2008') & (df['issue_d']<'2016')]\n",
    "\n",
    "# Convert to interest rate and revolving utilization to float\n",
    "df['int_rate'] = df['int_rate'].map(lambda x: float(x[:-1]) if type(x) == str else x)\n",
    "df['revol_util'] = df['revol_util'].map(lambda x: float(x[:-1]) if type(x) != float else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features that are good to use as-is and which features to dummify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_as_is = ['loan_amnt', 'int_rate', 'dti', 'annual_inc', 'delinq_2yrs', 'open_acc', 'revol_util', 'default']\n",
    "to_dummify = ['term', 'purpose', 'addr_state', 'home_ownership']\n",
    "\n",
    "df = df[to_dummify + cols_as_is]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummify categorical variables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dummify features\n",
    "for dummy_feat in to_dummify:\n",
    "    df = pd.concat([df, pd.get_dummies(df[dummy_feat], prefix=dummy_feat)],axis=1)\n",
    "\n",
    "# Drop un-dummified features\n",
    "df = df.drop(to_dummify, axis=1)\n",
    "    \n",
    "# Include dummified features in cols_to_use\n",
    "cols_to_use = [col for col in df.columns if col in cols_as_is or any([dummy_feat in col for dummy_feat in to_dummify])]\n",
    "\n",
    "# Drop NA and subset\n",
    "df = df[cols_to_use].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[cols_to_use].drop('default')\n",
    "y = df['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "split_data = {'X_train':X_train,\n",
    "             'y_train':y_train,\n",
    "             'X_test':X_test,\n",
    "             'y_test':y_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push processed data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent string to S3 with key 'demos/loan-risk/data/split_data.p'\n"
     ]
    }
   ],
   "source": [
    "s3_conn.push_file_to_s3(path=pickle.dumps(split_data),\n",
    "                        key='demos/loan-risk/data/split_data.p',\n",
    "                        string=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent string to S3 with key 'demos/loan-risk/data/feats.p'\n"
     ]
    }
   ],
   "source": [
    "feats = {'to_dummify':to_dummify,\n",
    "         'as_is': cols_as_is,\n",
    "         'trained_features': X_train.columns}\n",
    "\n",
    "s3_conn.push_file_to_s3(path=pickle.dumps(feats),\n",
    "                        key='demos/loan-risk/data/feats.p',\n",
    "                        string=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 81)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbed demos/loan-risk/models/RF.p from S3. Local file demos/loan-risk/models/RF.p is now available.\n"
     ]
    }
   ],
   "source": [
    "clf = s3_conn.pull_pickle_from_s3(key='demos/loan-risk/models/RF.p', tmp_localdir=tmp_localdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = X_test.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = raw.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'loan_amnt', u'int_rate', u'dti', u'annual_inc', u'delinq_2yrs',\n",
       "       u'open_acc', u'revol_util', u'term', u'purpose', u'addr_state',\n",
       "       u'home_ownership', u'default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dummify features\n",
    "for dummy_feat in feats['to_dummify']:\n",
    "    if dummy_feat in df:\n",
    "        df = pd.concat([df, pd.get_dummies(df[dummy_feat], prefix=dummy_feat)],axis=1)\n",
    "        \n",
    "        # Drop un-dummified features\n",
    "        df = df.drop(dummy_feat, axis=1)\n",
    "\n",
    "    \n",
    "# Include dummified features in cols_to_use\n",
    "cols_to_use = [col for col in df.columns if col in feats['as_is'] or any([dummy_feat in col for dummy_feat in feats['to_dummify']])]\n",
    "\n",
    "# Drop NA and subset\n",
    "df = df[cols_to_use].dropna()\n",
    "\n",
    "\n",
    "# If after dummifying we are missing any features wrt the training data feature space, add a column of zeros for that feature\n",
    "for training_feat in feats['trained_features']:\n",
    "    if training_feat not in df:\n",
    "        df[training_feat] = np.zeros((df.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24928368084606212"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\"addr_state\": \"AZ\",  \"annual_inc\": \"24000.0\",  \"delinq_2yrs\": \"0.0\",  \"dti\": \"27.649999999999999\",  \"home_ownership\": \"RENT\",  \"int_rate\": \"10.65\",  \"loan_amnt\": \"5000.0\",  \"open_acc\": \"3.0\",  \"purpose\": \"credit_card\",  \"revol_util\": \"83.700000000000003\",  \"term\": \" 36 months\"}\n",
    "\n",
    "predict_default_probability(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\"data\":\n",
    "     {\"addr_state\": \"AZ\",  \"annual_inc\": \"24000.0\",  \"delinq_2yrs\": \"0.0\",  \"dti\": \"27.649999999999999\",  \"home_ownership\": \"RENT\",  \"int_rate\": \"10.65\",  \"loan_amnt\": \"5000.0\",  \"open_acc\": \"3.0\",  \"purpose\": \"credit_card\",  \"revol_util\": \"83.700000000000003\",  \"term\": \" 36 months\"}\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
